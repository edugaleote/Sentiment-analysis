{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 585 - HW 3 - EDUARDO GALEOTE - A20552496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/edugaleote/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#NLTK setup - uncomment and run first time you import NLTK\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from csv import QUOTE_NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0       hide new secretions from the parental units       0\n",
       "1               contains no wit , only labored gags       0\n",
       "2  that loves its characters and communicates som...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sst = pd.read_csv(\"train.tsv\",delimiter=\"\\t\")\n",
    "df_sst.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 1 – Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation size: 100\n",
      "Test size: 100\n",
      "Training size: 67149\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "val_df = df_sst.iloc[:100]\n",
    "test_df = df_sst.iloc[100:200]\n",
    "train_df = df_sst.iloc[200:]\n",
    "\n",
    "# If you want to check the sizes:\n",
    "print(\"Validation size:\", len(val_df))\n",
    "print(\"Test size:\", len(test_df))\n",
    "print(\"Training size:\", len(train_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probability for positive sentiment: 0.5579681007907787\n",
      "Prior probability for negative sentiment: 0.44203189920922126\n"
     ]
    }
   ],
   "source": [
    "# Calculating the number of occurrences of each label in the training set\n",
    "num_positives = train_df['label'].sum()\n",
    "num_negatives = len(train_df) - num_positives\n",
    "\n",
    "# Calculating prior probabilities\n",
    "prior_positive = num_positives / len(train_df)\n",
    "prior_negative = num_negatives / len(train_df)\n",
    "\n",
    "print(\"Prior probability for positive sentiment:\", prior_positive)\n",
    "print(\"Prior probability for negative sentiment:\", prior_negative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 2 – Tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'hello', 'class', '</s>']\n"
     ]
    }
   ],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    # Tokenize the sentence by splitting based on whitespace\n",
    "    tokens = sentence.split()\n",
    "    \n",
    "    # Add start and end symbols to the tokenized sequence\n",
    "    return ['<s>'] + tokens + ['</s>']\n",
    "\n",
    "# Test the function\n",
    "sentence = \"hello class\"\n",
    "print(tokenize_sentence(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'told', 'in', 'scattered', 'fashion', '</s>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c6/n52lpdx173scrtd7wybk2_xh0000gn/T/ipykernel_4286/1389430574.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['tokenized'] = train_df['sentence'].apply(tokenize_sentence)\n"
     ]
    }
   ],
   "source": [
    "# Applying the function to the 'sentence' column\n",
    "train_df['tokenized'] = train_df['sentence'].apply(tokenize_sentence)\n",
    "\n",
    "# Displaying the tokenization of the first sentence\n",
    "print(train_df['tokenized'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (including <s> and </s> symbols): 14813\n"
     ]
    }
   ],
   "source": [
    "# Create a set to store the unique tokens\n",
    "vocab = set()\n",
    "\n",
    "# Iterate over each tokenized sentence and update the vocabulary set\n",
    "for tokens in train_df['tokenized']:\n",
    "    vocab.update(tokens)\n",
    "\n",
    "# Determine the size of the vocabulary\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(\"Vocabulary size (including <s> and </s> symbols):\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 3 – Bigram counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bigrams(tokenized_sequences):\n",
    "    # Initialize an empty dictionary to store bigram counts\n",
    "    bigram_counts = {}\n",
    "\n",
    "    # Iterate over each tokenized sentence\n",
    "    for tokens in tokenized_sequences:\n",
    "        for i in range(len(tokens) - 1):  # -1 because we're looking at pairs of tokens\n",
    "            # Get the current token and the next token\n",
    "            wi, wj = tokens[i], tokens[i + 1]\n",
    "            \n",
    "            # If wi is not in the dictionary, add it with an empty dictionary as its value\n",
    "            if wi not in bigram_counts:\n",
    "                bigram_counts[wi] = {}\n",
    "            \n",
    "            # If wj is not in the wi dictionary, add it with count 0\n",
    "            if wj not in bigram_counts[wi]:\n",
    "                bigram_counts[wi][wj] = 0\n",
    "\n",
    "            # Increment the count of the bigram (wi, wj)\n",
    "            bigram_counts[wi][wj] += 1\n",
    "            \n",
    "    return bigram_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "bigram_counts = count_bigrams(train_df['tokenized'].tolist())\n",
    "# Now, you can retrieve the count of any bigram using bigram_counts[wi][wj]\n",
    "print(bigram_counts[\"academy\"][\"award\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of times a sentence starts with 'the' is: 4450\n"
     ]
    }
   ],
   "source": [
    "count_start_the = bigram_counts.get('<s>', {}).get('the', 0)\n",
    "print(f\"The number of times a sentence starts with 'the' is: {count_start_the}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 4 – Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability for alpha=0.001: -1.0250904304166832\n",
      "Log probability for alpha=0.5: -6.172912066128204\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def smoothed_log_probability(wm, wm_1, bigram_counts, alpha, vocab_size):\n",
    "    # Count of all bigrams starting with wm_1\n",
    "    wm_1_count = sum(bigram_counts.get(wm_1, {}).values())\n",
    "    # Get the bigram count, if it doesn't exist in the dictionary, default to 0\n",
    "    bigram_count = bigram_counts.get(wm_1, {}).get(wm, 0)\n",
    "    # Implementing the formula for smoothed probability\n",
    "    p_smooth = (bigram_count + alpha) / (wm_1_count + vocab_size * alpha)\n",
    "\n",
    "    # Returning the negative log-probability\n",
    "    return math.log(p_smooth)\n",
    "\n",
    "# Calculating and printing the log probabilities for the given alphas\n",
    "for alpha in [0.001, 0.5]:\n",
    "    log_prob = smoothed_log_probability(\"award\", \"academy\", bigram_counts, alpha, vocab_size)\n",
    "    print(f\"Log probability for alpha={alpha}: {log_prob}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 5 – Sentence log-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of the sentence 'this was a really great movie but it was a little too long.': -85.38817424066075\n",
      "Log probability of the sentence 'long too little a was it but movie great really a was this.': -163.18320211328515\n"
     ]
    }
   ],
   "source": [
    "def sentence_log_probability(sentence, bigram_counts, alpha, vocab_size):\n",
    "    # Tokenize the sentence and add start and end symbols\n",
    "    tokens = ['<s>'] + sentence.split() + ['</s>']\n",
    "    \n",
    "    # Compute the sum of the log probabilities for each bigram in the sentence\n",
    "    log_prob = 0\n",
    "    for i in range(1, len(tokens)):\n",
    "        # Extract the current word and the previous word\n",
    "        wm, wm_1 = tokens[i], tokens[i-1]\n",
    "        \n",
    "        # Use the smoothed_log_probability to get the log-probability for each bigram\n",
    "        log_prob += smoothed_log_probability(wm, wm_1, bigram_counts, alpha, vocab_size)\n",
    "    \n",
    "    return log_prob\n",
    "\n",
    "# Sentences\n",
    "sentences = [\n",
    "    \"this was a really great movie but it was a little too long.\",\n",
    "    \"long too little a was it but movie great really a was this.\"\n",
    "]\n",
    "\n",
    "# Compute the log-probability for each sentence using the given alpha value\n",
    "alpha = 0.001\n",
    "for s in sentences:\n",
    "    log_prob = sentence_log_probability(s, bigram_counts, alpha, vocab_size)\n",
    "    print(f\"Log probability of the sentence '{s}': {log_prob}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 6 – Tuning Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood estimate for alpha 0.001: -47.23596387105087\n",
      "Log-likelihood estimate for alpha 0.01: -44.09395975180249\n",
      "Log-likelihood estimate for alpha 0.1: -41.70366084780157\n",
      "The selected alpha is: 0.1\n"
     ]
    }
   ],
   "source": [
    "def validation_log_likelihood(alpha, validation_data, bigram_counts, vocab_size):\n",
    "    # Calculate the sum of the log probabilities for all sentences in the validation set\n",
    "    total_log_prob = sum(sentence_log_probability(sentence, bigram_counts, alpha, vocab_size) for sentence in validation_data)\n",
    "    return total_log_prob\n",
    "\n",
    "# Given validation data\n",
    "validation_data = val_df\n",
    "\n",
    "# Different alpha values\n",
    "alphas = [0.001, 0.01, 0.1]\n",
    "\n",
    "# Calculate and print the log-likelihood estimates for each alpha\n",
    "log_likelihoods = {}\n",
    "for alpha in alphas:\n",
    "    log_likelihood = validation_log_likelihood(alpha, validation_data, bigram_counts, vocab_size)\n",
    "    log_likelihoods[alpha] = log_likelihood\n",
    "    print(f\"Log-likelihood estimate for alpha {alpha}: {log_likelihood}\")\n",
    "\n",
    "# Select the alpha with the highest log-likelihood (least negative value)\n",
    "selected_alpha = max(log_likelihoods, key=log_likelihoods.get)\n",
    "\n",
    "print(f\"The selected alpha is: {selected_alpha}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 7 – Applying Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Predicted Positives: 50\n",
      "Number of Predicted Negatives: 50\n",
      "Number of Correctly Predicted Positives: 50\n",
      "Number of Correctly Predicted Negatives: 47\n",
      "Number of Incorrectly Predicted Positives: 0\n",
      "Number of Incorrectly Predicted Negatives: 3\n",
      "Accuracy: 97.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c6/n52lpdx173scrtd7wybk2_xh0000gn/T/ipykernel_4286/1777016689.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predicted_label'] = predicted_labels\n"
     ]
    }
   ],
   "source": [
    "positive_sentences=pd.DataFrame()\n",
    "negative_sentences=pd.DataFrame()\n",
    "\n",
    "positive_sentences['sentence'] = df_sst[df_sst['label'] == 1]['sentence'].tolist()\n",
    "negative_sentences['sentence'] = df_sst[df_sst['label'] == 0]['sentence'].tolist()\n",
    "\n",
    "positive_sentences['tokenized'] = positive_sentences['sentence'].apply(tokenize_sentence)\n",
    "negative_sentences['tokenized'] = negative_sentences['sentence'].apply(tokenize_sentence)\n",
    "\n",
    "positive_bigram_counts = count_bigrams(positive_sentences['tokenized'].tolist())\n",
    "negative_bigram_counts = count_bigrams(negative_sentences['tokenized'].tolist())\n",
    "\n",
    "posvocab = set()\n",
    "\n",
    "for tokens in positive_sentences['tokenized']:\n",
    "    posvocab.update(tokens)\n",
    "\n",
    "posvocab_size = len(posvocab)\n",
    "\n",
    "negvocab = set()\n",
    "\n",
    "for tokens in negative_sentences['tokenized']:\n",
    "    negvocab.update(tokens)\n",
    "\n",
    "negvocab_size = len(negvocab)\n",
    "\n",
    "predicted_labels = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    sentence = row['sentence']\n",
    "    \n",
    "    positive_score = sentence_log_probability(sentence, positive_bigram_counts, selected_alpha, posvocab_size) + prior_positive\n",
    "    negative_score = sentence_log_probability(sentence, negative_bigram_counts, selected_alpha, negvocab_size) + prior_negative\n",
    "    \n",
    "    if positive_score > negative_score:\n",
    "        predicted_labels.append(1)\n",
    "    else:\n",
    "        predicted_labels.append(0)\n",
    "\n",
    "test_df['predicted_label'] = predicted_labels\n",
    "\n",
    "# Count the number of positive and negative predicted labels\n",
    "num_predicted_positives = test_df[test_df['predicted_label'] == 1].shape[0]\n",
    "num_predicted_negatives = test_df[test_df['predicted_label'] == 0].shape[0]\n",
    "\n",
    "print(f\"Number of Predicted Positives: {num_predicted_positives}\")\n",
    "print(f\"Number of Predicted Negatives: {num_predicted_negatives}\")\n",
    "\n",
    "# Count the number of correctly predicted labels\n",
    "correctly_predicted_positives = test_df[(test_df['label'] == 1) & (test_df['predicted_label'] == 1)].shape[0]\n",
    "correctly_predicted_negatives = test_df[(test_df['label'] == 0) & (test_df['predicted_label'] == 0)].shape[0]\n",
    "\n",
    "print(f\"Number of Correctly Predicted Positives: {correctly_predicted_positives}\")\n",
    "print(f\"Number of Correctly Predicted Negatives: {correctly_predicted_negatives}\")\n",
    "\n",
    "# Count the number of incorrectly predicted labels\n",
    "incorrectly_predicted_positives = num_predicted_positives - correctly_predicted_positives\n",
    "incorrectly_predicted_negatives = num_predicted_negatives - correctly_predicted_negatives\n",
    "\n",
    "print(f\"Number of Incorrectly Predicted Positives: {incorrectly_predicted_positives}\")\n",
    "print(f\"Number of Incorrectly Predicted Negatives: {incorrectly_predicted_negatives}\")\n",
    "\n",
    "correct_predictions = (test_df['label'] == test_df['predicted_label']).sum()\n",
    "total_predictions = len(test_df)\n",
    "accuracy = correct_predictions / total_predictions * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
